From 6edc0e9fb081886771c27086dcc08d0af9682748 Mon Sep 17 00:00:00 2001
From: Ting Fu <ting.fu@intel.com>
Date: Wed, 29 Jun 2022 07:46:44 +0000
Subject: [PATCH 4/4] lavf/dnn: enable libtorch backend support FRVSR model

Signed-off-by: Ting Fu <ting.fu@intel.com>
---
 libavfilter/dnn/dnn_backend_torch.cpp | 52 +++++++++++++++++++++++----
 1 file changed, 45 insertions(+), 7 deletions(-)

diff --git a/libavfilter/dnn/dnn_backend_torch.cpp b/libavfilter/dnn/dnn_backend_torch.cpp
index fde0a022ae..cefbca068d 100644
--- a/libavfilter/dnn/dnn_backend_torch.cpp
+++ b/libavfilter/dnn/dnn_backend_torch.cpp
@@ -46,6 +46,8 @@ typedef struct THContext {
     THOptions options;
 } THContext;
 
+typedef enum {UNKNOWN_MODEL = -1, BASICVSR, FRVSR} ModelType;
+
 typedef struct THModel {
     THContext ctx;
     DNNModel *model;
@@ -53,6 +55,7 @@ typedef struct THModel {
     SafeQueue *request_queue;
     Queue *task_queue;
     Queue *lltask_queue;
+    ModelType model_type;
 } THModel;
 
 typedef struct THInferRequest {
@@ -242,6 +245,7 @@ DNNModel *ff_dnn_load_model_th(const char *model_filename, DNNFunctionType func_
         av_log(ctx, AV_LOG_ERROR, "Failed to load torch model\n");
         goto fail;
     }
+    const torch::jit::NameTensor& first_param = *th_model->jit_model.named_parameters().begin();
 
     th_model->request_queue = ff_safe_queue_create();
     if (!th_model->request_queue) {
@@ -276,6 +280,13 @@ DNNModel *ff_dnn_load_model_th(const char *model_filename, DNNFunctionType func_
         goto fail;
     }
 
+    if (!first_param.name.find("fnet")) {
+        th_model->model_type = FRVSR;
+    } else if (!first_param.name.find("spynet")) {
+        th_model->model_type = BASICVSR;
+    } else {
+        th_model->model_type = UNKNOWN_MODEL;
+    }
     th_model->model = model;
     model->model = th_model;
     model->get_input = &get_input_th;
@@ -341,8 +352,13 @@ static int fill_model_input_th(THModel *th_model, THRequestItem *request)
         avpriv_report_missing_feature(NULL, "model function type %d", th_model->model->func_type);
         break;
     }
-    *infer_request->input_tensor = torch::from_blob(input.data, {1, 1, 3, input.height, input.width},
-                                                    torch::kFloat32);
+    if (th_model->model_type == FRVSR) {
+        *infer_request->input_tensor = torch::from_blob(input.data, {1, 3, input.height, input.width},
+                                                        torch::kFloat32);
+    } else {
+        *infer_request->input_tensor = torch::from_blob(input.data, {1, 1, 3, input.height, input.width},
+                                                        torch::kFloat32);
+    }
     if (infer_request->input_tensor->device() != ctx->options.device_type)
         *infer_request->input_tensor = infer_request->input_tensor->to(ctx->options.device_type);
     return 0;
@@ -361,6 +377,7 @@ static int th_start_inference(void *args)
     THModel *th_model = NULL;
     THContext *ctx = NULL;
     std::vector<torch::jit::IValue> inputs;
+    c10::DeviceType device_type;
 
     if (!request) {
         av_log(NULL, AV_LOG_ERROR, "THRequestItem is NULL\n");
@@ -371,14 +388,31 @@ static int th_start_inference(void *args)
     task = lltask->task;
     th_model = (THModel *)task->model;
     ctx = &th_model->ctx;
+    device_type = ctx->options.device_type;
 
     if (!infer_request->input_tensor || !infer_request->output) {
         av_log(ctx, AV_LOG_ERROR, "input or output tensor is NULL\n");
         return DNN_GENERIC_ERROR;
     }
     inputs.push_back(*infer_request->input_tensor);
-
-    *infer_request->output = th_model->jit_model.forward(inputs).toTensor();
+    if (th_model->model_type == FRVSR) {
+        auto size = infer_request->input_tensor->sizes();
+        int height = size[2];
+        int width  = size[3];
+        torch::Tensor lr_prev = torch::zeros({1, 3, height, width}, torch::TensorOptions().dtype(torch::kFloat32)
+                                                                                          .device(device_type));
+        torch::Tensor hr_prev = torch::zeros({1, 3, height * 4, width * 4}, torch::TensorOptions().dtype(torch::kFloat32)
+                                                                                                  .device(device_type));
+        inputs.push_back(lr_prev);
+        inputs.push_back(hr_prev);
+    }
+
+    auto outputs = th_model->jit_model.forward(inputs);
+    if (th_model->model_type == FRVSR) {
+        *infer_request->output = outputs.toTuple()->elements()[0].toTensor();
+    } else {
+        *infer_request->output = outputs.toTensor();
+    }
 
     return 0;
 }
@@ -393,10 +427,14 @@ static void infer_completion_callback(void *args) {
     torch::Tensor *output = infer_request->output;
 
     c10::IntArrayRef sizes = output->sizes();
-    assert(sizes.size == 5);
+    if (th_model->model_type == FRVSR) {
+        outputs.height = sizes.at(2);
+        outputs.width = sizes.at(3);
+    } else {
+        outputs.height = sizes.at(3);
+        outputs.width = sizes.at(4);
+    }
     outputs.order = DCO_RGB_PLANAR;
-    outputs.height = sizes.at(3);
-    outputs.width = sizes.at(4);
     outputs.dt = DNN_FLOAT;
     outputs.channels = 3;
 
-- 
2.17.1

