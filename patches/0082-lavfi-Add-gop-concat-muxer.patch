From 5a19efffcc96ad0c6188d866bab5b40dfb68c871 Mon Sep 17 00:00:00 2001
From: Fei Wang <fei.w.wang@intel.com>
Date: Fri, 2 Sep 2022 16:45:03 +0800
Subject: [PATCH] lavfi: Add gop concat muxer

Gop concat can connect two different input streams into one stream GOP
by GOP. It picks up two GOP from different streams, and order the GOP
from second stream after the GOP from the first stream. The GOP in two
stream must be closed GOP, which its frames will not reference other frame
out of the current GOP. Some code reference fifo muxer.

One use case is that in multi device hardware transcode, general
transcode will use same hardware both in decoding and encoding. Then the
left device will not be used. Now we can use diffenent hardware for
transcode and select different frames to encode. And re-connect the
output from encoding by using gop concat.

Note: Option ignore_ts added in ffmpeg.c used with gopconcat muxer can
improve performance. It ignores check timestamp get from filter for each
stream, so that all frames can be decoded stream by stream without any
priority and delay. For the below example, when ffmpeg start decode 2
streams, the frames in 1st gop of 1st stream all can be selected in
filter and frame's TS can be obtained, but the frames in 1st gop of 2nd
stream will be drop and TS always in NULL in filter side. This will lead
the 1st stream being decoded until TS obtained from filter in 2nd gop
frames of 2nd stream. And add the ignore_ts option will decode all
streams frame by frame without considering its TS get from filter side.

The example cmdline:
ffmpeg -ignore_ts -init_hw_device qsv=hw0:hw_any,child_device=/dev/dri/renderD128 \
-init_hw_device qsv=hw1:hw_any,child_device=/dev/dri/renderD129 \
-hwaccel qsv -hwaccel_device hw0 -extra_hw_frames 20 -c:v hevc_qsv \
-async_depth 10 -itsoffset 1 -i hevc.mp4 \
-hwaccel qsv -hwaccel_device hw1 -extra_hw_frames 20 -c:v hevc_qsv \
-async_depth 10 -i hevc.mp4 \
-map 0:v -filter:v:0 select='not(mod(floor(n/60)\,2))' -vsync 0 \
-c:v:0 hevc_qsv -async_depth 10 -g 60 \
-map 1:v -filter:v:1 select='mod(floor(n/60)\,2)' -vsync 0 \
-c:v:1 hevc_qsv -async_depth 10 -g 60 \
-f gop_concat -gop_size 60 -y out.mp4
---
 fftools/ffmpeg.c           |  25 ++-
 fftools/ffmpeg.h           |   1 +
 fftools/ffmpeg_opt.c       |   3 +
 libavformat/Makefile       |   1 +
 libavformat/allformats.c   |   1 +
 libavformat/gopconcatenc.c | 344 +++++++++++++++++++++++++++++++++++++
 6 files changed, 372 insertions(+), 3 deletions(-)
 create mode 100644 libavformat/gopconcatenc.c

diff --git a/fftools/ffmpeg.c b/fftools/ffmpeg.c
index 6e445427761d..92c02e482a43 100644
--- a/fftools/ffmpeg.c
+++ b/fftools/ffmpeg.c
@@ -2295,6 +2295,8 @@ static OutputStream *choose_output(void)
 {
     int64_t opts_min = INT64_MAX;
     OutputStream *ost_min = NULL;
+    static OutputStream *prev_video_ost = NULL;
+    int available_video_number = 0;
 
     for (OutputStream *ost = ost_iter(NULL); ost; ost = ost_iter(ost)) {
         int64_t opts;
@@ -2313,11 +2315,28 @@ static OutputStream *choose_output(void)
         if (!ost->initialized && !ost->inputs_done && !ost->finished)
             return ost->unavailable ? NULL : ost;
 
-        if (!ost->finished && opts < opts_min) {
-            opts_min = opts;
-            ost_min  = ost->unavailable ? NULL : ost;
+        if (ignore_ts) {
+            if (ost->st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO && !ost->finished)
+                available_video_number++;
+
+            if (!ost->finished && opts < opts_min && (ost != prev_video_ost)) {
+                opts_min = opts;
+                ost_min  = ost->unavailable ? NULL : ost;
+            }
+        } else {
+            if (!ost->finished && opts < opts_min) {
+                opts_min = opts;
+                ost_min  = ost->unavailable ? NULL : ost;
+            }
         }
     }
+
+    if (ost_min && ost_min->st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO)
+        prev_video_ost = ost_min;
+    // reset prev video ost to NULL when only 1 not finished video stream exist.
+    if (available_video_number == 1)
+        prev_video_ost = NULL;
+
     return ost_min;
 }
 
diff --git a/fftools/ffmpeg.h b/fftools/ffmpeg.h
index 17076f018d6b..29f82fb06ff0 100644
--- a/fftools/ffmpeg.h
+++ b/fftools/ffmpeg.h
@@ -754,6 +754,7 @@ extern int64_t stats_period;
 extern int stdin_interaction;
 extern AVIOContext *progress_avio;
 extern float max_error_rate;
+extern int ignore_ts;
 
 extern char *filter_nbthreads;
 extern int filter_complex_nbthreads;
diff --git a/fftools/ffmpeg_opt.c b/fftools/ffmpeg_opt.c
index aa9aa0e9b45a..253299ab9e33 100644
--- a/fftools/ffmpeg_opt.c
+++ b/fftools/ffmpeg_opt.c
@@ -87,6 +87,7 @@ int filter_complex_nbthreads = 0;
 int vstats_version = 2;
 int auto_conversion_filters = 1;
 int64_t stats_period = 500000;
+int ignore_ts = 0;
 
 
 static int file_overwrite     = 0;
@@ -1779,6 +1780,8 @@ const OptionDef options[] = {
         "initialise hardware device", "args" },
     { "filter_hw_device", HAS_ARG | OPT_EXPERT, { .func_arg = opt_filter_hw_device },
         "set hardware device used when filtering", "device" },
+    { "ignore_ts",      OPT_BOOL | OPT_EXPERT, { &ignore_ts },
+        "ignore ts of different stream and cross output stream by steam" },
 
     { NULL, },
 };
diff --git a/libavformat/Makefile b/libavformat/Makefile
index 048649689b17..fa0cf28a737d 100644
--- a/libavformat/Makefile
+++ b/libavformat/Makefile
@@ -224,6 +224,7 @@ OBJS-$(CONFIG_FSB_DEMUXER)               += fsb.o
 OBJS-$(CONFIG_FWSE_DEMUXER)              += fwse.o pcm.o
 OBJS-$(CONFIG_GIF_MUXER)                 += gif.o
 OBJS-$(CONFIG_GIF_DEMUXER)               += gifdec.o
+OBJS-$(CONFIG_GOP_CONCAT_MUXER)          += gopconcatenc.o
 OBJS-$(CONFIG_GSM_DEMUXER)               += gsmdec.o
 OBJS-$(CONFIG_GSM_MUXER)                 += rawenc.o
 OBJS-$(CONFIG_GXF_DEMUXER)               += gxf.o
diff --git a/libavformat/allformats.c b/libavformat/allformats.c
index cb5b69e9cd6c..de5e36905541 100644
--- a/libavformat/allformats.c
+++ b/libavformat/allformats.c
@@ -189,6 +189,7 @@ extern const AVInputFormat  ff_gdv_demuxer;
 extern const AVInputFormat  ff_genh_demuxer;
 extern const AVInputFormat  ff_gif_demuxer;
 extern const FFOutputFormat ff_gif_muxer;
+extern const FFOutputFormat ff_gop_concat_muxer;
 extern const AVInputFormat  ff_gsm_demuxer;
 extern const FFOutputFormat ff_gsm_muxer;
 extern const AVInputFormat  ff_gxf_demuxer;
diff --git a/libavformat/gopconcatenc.c b/libavformat/gopconcatenc.c
new file mode 100644
index 000000000000..8dceaddb0392
--- /dev/null
+++ b/libavformat/gopconcatenc.c
@@ -0,0 +1,344 @@
+/*
+ * Stream merge muxer
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "avformat.h"
+#include "internal.h"
+#include "mux.h"
+
+#include "libavutil/opt.h"
+#include "libavcodec/packet_internal.h"
+
+#define TOTAL_VIDEO_STREAMS 2
+
+typedef struct GopConcatMuxContext {
+    const AVClass *class;
+    AVFormatContext *avf;
+    AVDictionary *format_options;
+    PacketList pkt_list;
+    // current input video stream idx
+    unsigned int stream_idx;
+    int output_number;
+    unsigned int gop_counter;
+
+    // video/audio idx in avf.streams
+    unsigned int video_idx;
+    unsigned int audio_idx;
+
+    uint8_t header_written;
+    // user options
+    char *format;
+    int gop_size;
+} GopConcatMuxContext;
+
+static av_cold int gop_concat_init(AVFormatContext *ctx)
+{
+    GopConcatMuxContext *s = ctx->priv_data;
+    const AVOutputFormat *oformat;
+    AVFormatContext *avf2;
+    AVStream *st;
+    int has_video = 0, has_audio = 0;
+    int ret;
+
+    oformat = av_guess_format(s->format, ctx->url, NULL);
+    if (!oformat) {
+        ret = AVERROR_MUXER_NOT_FOUND;
+        return ret;
+    }
+
+    ret = avformat_alloc_output_context2(&avf2, oformat, NULL, ctx->url);
+    if (ret < 0)
+        return ret;
+
+    s->avf = avf2;
+
+    avf2->interrupt_callback = ctx->interrupt_callback;
+    avf2->max_delay = ctx->max_delay;
+    ret = av_dict_copy(&avf2->metadata, ctx->metadata, 0);
+    if (ret < 0)
+        return ret;
+    avf2->opaque = ctx->opaque;
+#if FF_API_AVFORMAT_IO_CLOSE
+FF_DISABLE_DEPRECATION_WARNINGS
+    avf2->io_close = ctx->io_close;
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+    avf2->io_close2 = ctx->io_close2;
+    avf2->io_open = ctx->io_open;
+    avf2->flags = ctx->flags;
+
+    // create one video output stream.
+    for (int i = 0; i < ctx->nb_streams; ++i) {
+        if (ctx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {
+            if (!has_audio) {
+                st = ff_stream_clone(avf2, ctx->streams[i]);
+                if (!st)
+                    return AVERROR(ENOMEM);
+                s->audio_idx = avf2->nb_streams - 1;
+                has_audio = 1;
+            }
+        } else if (ctx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
+            if (!has_video) {
+                st = ff_stream_clone(avf2, ctx->streams[i]);
+                if (!st)
+                    return AVERROR(ENOMEM);
+                s->video_idx = avf2->nb_streams - 1;
+                has_video = 1;
+            }
+        }
+    }
+
+    return 0;
+}
+
+static int gop_concat_write_header(AVFormatContext *ctx)
+{
+    GopConcatMuxContext *s = ctx->priv_data;
+    AVFormatContext *avf2 = s->avf;
+    AVDictionary *format_options = NULL;
+    int ret, i;
+
+    ret = av_dict_copy(&format_options, s->format_options, 0);
+    if (ret < 0)
+        goto end;
+
+    ret = ff_format_output_open(avf2, ctx->url, &format_options);
+    if (ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "Error opening %s: %s\n", ctx->url,
+               av_err2str(ret));
+        goto end;
+    }
+
+    for (i = 0;i < avf2->nb_streams; i++)
+        ffstream(avf2->streams[i])->cur_dts = 0;
+
+    ret = avformat_write_header(avf2, &format_options);
+    if (!ret)
+        s->header_written = 1;
+
+    // Check for options unrecognized by underlying muxer
+    if (format_options) {
+        AVDictionaryEntry *entry = NULL;
+        while ((entry = av_dict_get(format_options, "", entry, AV_DICT_IGNORE_SUFFIX)))
+            av_log(avf2, AV_LOG_ERROR, "Unknown option '%s'\n", entry->key);
+        ret = AVERROR(EINVAL);
+    }
+
+end:
+    av_dict_free(&format_options);
+    return ret;
+}
+
+static void packet_list_remove(PacketList *pkt_list, PacketListEntry *pktl, PacketListEntry *prev)
+{
+    if (prev) {
+        if (pktl->next)
+            prev->next = pktl->next;
+        else {
+            prev->next = NULL;
+            pkt_list->tail = prev;
+        }
+    } else {
+        if (pktl->next)
+            pkt_list->head = pktl->next;
+        else {
+            pkt_list->head = NULL;
+            pkt_list->tail = NULL;
+        }
+    }
+    av_freep(&pktl);
+}
+
+static int send_output_pkt(AVFormatContext *ctx)
+{
+    GopConcatMuxContext *s = ctx->priv_data;
+    AVFormatContext *avf2 = s->avf;
+    PacketListEntry *pktl, *prev_pktl = NULL;
+    AVPacket *pkt = NULL;
+    AVRational src_tb, dst_tb;
+    int ret;
+
+    pktl = s->pkt_list.head;
+    while (pktl) {
+        pkt = &pktl->pkt;
+        if (pkt->stream_index == s->stream_idx) {
+
+            av_log(s, AV_LOG_DEBUG, "Send video output pkt idx:%d, pts:%ld, dts:%ld, size:%d\n",
+                   pkt->stream_index, pkt->pts, pkt->dts, pkt->size);
+
+            // force to push pkt to video output stream.
+            pkt->stream_index = s->video_idx;
+
+            pkt->pts += (s->gop_counter/TOTAL_VIDEO_STREAMS + s->stream_idx) * s->gop_size;
+            pkt->dts += (s->gop_counter/TOTAL_VIDEO_STREAMS + s->stream_idx) * s->gop_size;
+
+            src_tb = ctx->streams[0]->time_base;
+            dst_tb = avf2->streams[0]->time_base;
+            av_packet_rescale_ts(pkt, src_tb, dst_tb);
+
+            ret = av_write_frame(avf2, pkt);
+            if (ret < 0) {
+                av_log(s, AV_LOG_ERROR, "Failed to send output pkt.\n");
+                return ret;
+            }
+            av_packet_unref(pkt);
+            // remove from list
+            packet_list_remove(&s->pkt_list, pktl, prev_pktl);
+            if (++s->output_number == s->gop_size) {
+                s->gop_counter++;
+                s->output_number = 0;
+
+                while (++s->stream_idx) {
+                    if (s->stream_idx == ctx->nb_streams)
+                        s->stream_idx = 0;
+                    if (ctx->streams[s->stream_idx]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
+                        av_log(s, AV_LOG_DEBUG, "Switch input index %d for video output.\n", s->stream_idx);
+                        break;
+                    }
+                }
+            }
+        } else
+            prev_pktl = pktl;
+
+        pktl = prev_pktl ? prev_pktl->next : s->pkt_list.head;
+    }
+
+    return 0;
+}
+
+static int gop_concat_write_packet(AVFormatContext *ctx, AVPacket *pkt)
+{
+    GopConcatMuxContext *s = ctx->priv_data;
+    AVFormatContext *avf2 = s->avf;
+    int ret;
+
+    av_log(s, AV_LOG_DEBUG, "Input pkt idx:%d, pts:%ld, dts:%ld, size:%d-\n",
+           pkt->stream_index, pkt->pts, pkt->dts, pkt->size);
+    // pass through audio pkt.
+    if (ctx->streams[pkt->stream_index]->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {
+        av_log(s, AV_LOG_DEBUG, "<- send audio output pkt idx:%d, pts:%ld, dts:%ld, size:%d\n",
+               pkt->stream_index, pkt->pts, pkt->dts, pkt->size);
+        pkt->stream_index = s->audio_idx;
+        ret = av_write_frame(avf2, pkt);
+        if (ret < 0) {
+            av_log(s, AV_LOG_ERROR, "Failed to send output pkt.\n");
+        }
+
+        return ret;
+    }
+
+    ret = avpriv_packet_list_put(&s->pkt_list, pkt, NULL, 0);
+    if (ret < 0) {
+        av_log(s, AV_LOG_ERROR, "Failed to put pkt to list.\n");
+        avpriv_packet_list_free(&s->pkt_list);
+        return ret;
+    }
+
+    ret = send_output_pkt(ctx);
+    if (ret < 0) {
+        av_log(s, AV_LOG_ERROR, "Failed to send output pkt.\n");
+        return ret;
+    }
+
+    return 0;
+}
+
+static av_cold int gop_concat_write_trailer(AVFormatContext *ctx)
+{
+    GopConcatMuxContext *s = ctx->priv_data;
+    AVFormatContext *avf2 = s->avf;
+    PacketListEntry *pktl, *prev_pktl;
+    AVPacket *pkt = NULL;
+    AVRational src_tb, dst_tb;
+    int ret, i;
+
+    if (!s->header_written)
+        return 0;
+    for (i = 0; i < ctx->nb_streams; i++) {
+        pktl = s->pkt_list.head;
+        prev_pktl = NULL;
+        while (pktl) {
+            pkt = &pktl->pkt;
+            if (pkt->stream_index == i) {
+                // avio_write(ctx->pb, pkt->data, pkt->size);
+                pkt->stream_index = s->video_idx;
+
+                pkt->pts += (s->gop_counter/TOTAL_VIDEO_STREAMS + s->stream_idx) * s->gop_size;
+                pkt->dts += (s->gop_counter/TOTAL_VIDEO_STREAMS + s->stream_idx) * s->gop_size;
+
+                src_tb = ctx->streams[0]->time_base;
+                dst_tb = avf2->streams[0]->time_base;
+                av_packet_rescale_ts(pkt, src_tb, dst_tb);
+
+                ret = av_write_frame(avf2, pkt);
+                if (ret < 0) {
+                    av_log(s, AV_LOG_ERROR, "Failed to send output pkt.\n");
+                    return ret;
+                }
+                av_packet_unref(pkt);
+                packet_list_remove(&s->pkt_list, pktl, prev_pktl);
+            } else
+                prev_pktl = pktl;
+
+            pktl = prev_pktl ? prev_pktl->next : s->pkt_list.head;
+       }
+    }
+    ret = av_write_trailer(avf2);
+    ff_format_io_close(avf2, &avf2->pb);
+
+    return ret;
+}
+
+static void gop_concat_deinit(AVFormatContext *ctx)
+{
+    GopConcatMuxContext *s = ctx->priv_data;
+
+    avformat_free_context(s->avf);
+}
+
+#define OFFSET(x) offsetof(GopConcatMuxContext, x)
+#define ENC AV_OPT_FLAG_ENCODING_PARAM
+static const AVOption options[] = {
+    {"concat_format", "Target muxer", OFFSET(format),
+      AV_OPT_TYPE_STRING, {.str = NULL}, 0, 0, ENC},
+    { "gop_size", "Number of frames in each gop.", OFFSET(gop_size),
+      AV_OPT_TYPE_INT, { .i64 = 1 }, 0, UINT16_MAX, ENC },
+    { NULL },
+};
+
+static const AVClass gop_concat_muxer_class = {
+    .class_name = "gop_concat",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT
+};
+
+const FFOutputFormat ff_gop_concat_muxer = {
+    .p.name         = "gop_concat",
+    .p.long_name    = NULL_IF_CONFIG_SMALL("gop concat muxer"),
+    .p.priv_class   = &gop_concat_muxer_class,
+    .p.flags        = AVFMT_GLOBALHEADER,
+    .priv_data_size = sizeof(GopConcatMuxContext),
+    .init           = gop_concat_init,
+    .write_header   = gop_concat_write_header,
+    .write_packet   = gop_concat_write_packet,
+    .write_trailer  = gop_concat_write_trailer,
+    .deinit         = gop_concat_deinit,
+
+};
-- 
2.38.1

