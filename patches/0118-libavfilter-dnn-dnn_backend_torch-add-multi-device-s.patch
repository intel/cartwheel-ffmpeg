From 7413fad25a13b4d8c94abfe67dfb198c91e5a14f Mon Sep 17 00:00:00 2001
From: Wenbin Chen <wenbin.chen@intel.com>
Date: Mon, 20 Nov 2023 14:32:26 +0800
Subject: [PATCH] libavfilter/dnn/dnn_backend_torch: add multi-device support

Now ffmpeg-libtoch can be run on multi-device at same time. When set device
user need to input all devices splited by '&' and also set async=1. The
inference tasks will be distributed to idle device dynamically.

example command:
ffmpeg -i input.mp4 -vf dnn_processing=dnn_backend=torch:model=model.pt:backend_configs="device='xpu\\\&cpu'"  output.mp4

Signed-off-by: Wenbin Chen <wenbin.chen@intel.com>
---
 libavfilter/dnn/dnn_backend_common.c  |   1 -
 libavfilter/dnn/dnn_backend_common.h  |   1 +
 libavfilter/dnn/dnn_backend_torch.cpp | 114 +++++++++++++++++++-------
 3 files changed, 87 insertions(+), 29 deletions(-)

diff --git a/libavfilter/dnn/dnn_backend_common.c b/libavfilter/dnn/dnn_backend_common.c
index 6eb90ba963..4dbe96517c 100644
--- a/libavfilter/dnn/dnn_backend_common.c
+++ b/libavfilter/dnn/dnn_backend_common.c
@@ -139,7 +139,6 @@ int ff_dnn_start_inference_async(void *ctx, DNNAsyncExecModule *async_module)
 DNNAsyncStatusType ff_dnn_get_result_common(Queue *task_queue, AVFrame **in, AVFrame **out)
 {
     TaskItem *task = ff_queue_peek_front(task_queue);
-
     if (!task) {
         return DAST_EMPTY_QUEUE;
     }
diff --git a/libavfilter/dnn/dnn_backend_common.h b/libavfilter/dnn/dnn_backend_common.h
index 2844804b36..f694657fce 100644
--- a/libavfilter/dnn/dnn_backend_common.h
+++ b/libavfilter/dnn/dnn_backend_common.h
@@ -54,6 +54,7 @@ typedef struct TaskItem {
     uint32_t nb_output;
     uint32_t inference_todo;
     uint32_t inference_done;
+    uint32_t device_idx;
 } TaskItem;
 
 // one task might have multiple inferences
diff --git a/libavfilter/dnn/dnn_backend_torch.cpp b/libavfilter/dnn/dnn_backend_torch.cpp
index da1d07409b..e13d774dcf 100644
--- a/libavfilter/dnn/dnn_backend_torch.cpp
+++ b/libavfilter/dnn/dnn_backend_torch.cpp
@@ -30,6 +30,7 @@ extern "C" {
 #include "../internal.h"
 #include "dnn_io_proc.h"
 #include "dnn_backend_common.h"
+#include "libavutil/avstring.h"
 #include "libavutil/fifo.h"
 #include "libavutil/opt.h"
 #include "libavutil/mem.h"
@@ -48,11 +49,15 @@ typedef struct THModel {
     Queue *lltask_queue;
     c10::DeviceType device_type;
     ModelType model_type;
+    char **device_names;
+    int nb_models;
+    SafeQueue *jit_model_queue;
 } THModel;
 
 typedef struct THInferRequest {
     torch::Tensor *output;
     torch::Tensor *input_tensor;
+    torch::jit::Module *jit_model;
 } THInferRequest;
 
 typedef struct THRequestItem {
@@ -71,6 +76,29 @@ static const AVOption dnn_th_options[] = {
 
 static void dnn_free_model_th(DNNModel **model);
 
+static char **th_separate_device_name(char *device_str, int *nb_devices)
+{
+    char *saveptr = NULL;
+    char **device_names;
+    int i = 0;
+    *nb_devices = 0;
+    while(device_str[i] != '\0') {
+        if(device_str[i] == '&')
+            *nb_devices += 1;
+        i++;
+    }
+    *nb_devices += 1;
+    device_names = (char **)av_mallocz(*nb_devices * sizeof(*device_names));
+    if (!device_names)
+        return NULL;
+
+    for (int i = 0; i < *nb_devices; i++) {
+        device_names[i] = av_strtok(device_str, "&", &saveptr);
+        device_str = NULL;
+    }
+    return device_names;
+}
+
 static int extract_lltask_from_task(TaskItem *task, Queue *lltask_queue)
 {
     THModel *th_model = (THModel *)task->model;
@@ -146,7 +174,12 @@ static void dnn_free_model_th(DNNModel **model)
         av_freep(&item);
     }
     ff_queue_destroy(th_model->task_queue);
-    delete th_model->jit_model;
+    while (ff_safe_queue_size(th_model->jit_model_queue) != 0) {
+        torch::jit::Module *jit_model = (torch::jit::Module *)ff_safe_queue_pop_front(th_model->jit_model_queue);
+        delete jit_model;
+    }
+    ff_safe_queue_destroy(th_model->jit_model_queue);
+    av_freep(&th_model->device_names);
     av_freep(&th_model);
     *model = NULL;
 }
@@ -193,6 +226,13 @@ static int fill_model_input_th(THModel *th_model, THRequestItem *request)
     if ( ret != 0) {
         goto err;
     }
+
+    infer_request->jit_model = (torch::jit::Module *)ff_safe_queue_pop_front(th_model->jit_model_queue);
+    if (!infer_request->jit_model) {
+        av_log(ctx, AV_LOG_ERROR, "unable to get jit_model.\n");
+        return AVERROR(EINVAL);
+    }
+
     width_idx = dnn_get_width_idx_by_layout(input.layout);
     height_idx = dnn_get_height_idx_by_layout(input.layout);
     channel_idx = dnn_get_channel_idx_by_layout(input.layout);
@@ -238,8 +278,6 @@ static int fill_model_input_th(THModel *th_model, THRequestItem *request)
             {1, task->nb_input, input.dims[channel_idx], input.dims[height_idx], input.dims[width_idx]},
             deleter, torch::kFloat32);
     }
-    if (infer_request->input_tensor->device() != th_model->device_type)
-        *infer_request->input_tensor = infer_request->input_tensor->to(th_model->device_type);
     return 0;
 
 err:
@@ -279,6 +317,9 @@ static int th_start_inference(void *args)
         av_log(ctx, AV_LOG_ERROR, "input or output tensor is NULL\n");
         return DNN_GENERIC_ERROR;
     }
+    c10::Device device = (*infer_request->jit_model->parameters().begin()).device();
+    if (infer_request->input_tensor->device() != device)
+        *infer_request->input_tensor = infer_request->input_tensor->to(device);
     inputs.push_back(*infer_request->input_tensor);
 
     if (th_model->model_type == FRVSR) {
@@ -293,7 +334,7 @@ static int th_start_inference(void *args)
         inputs.push_back(hr_prev);
     }
 
-    auto outputs = th_model->jit_model->forward(inputs);
+    auto outputs = infer_request->jit_model->forward(inputs);
     if (th_model->model_type == FRVSR) {
         *infer_request->output = outputs.toTuple()->elements()[0].toTensor();
     } else {
@@ -369,7 +410,11 @@ static void infer_completion_callback(void *args) {
     av_freep(&request->lltask);
 err:
     th_free_request(infer_request);
-
+    if (ff_safe_queue_push_back(th_model->jit_model_queue, infer_request->jit_model) < 0) {
+        delete infer_request->jit_model;
+        av_log(&th_model->ctx, AV_LOG_ERROR, "Unable to push back jit_model when failed to start inference.\n");
+    }
+    infer_request->jit_model = NULL;
     if (ff_safe_queue_push_back(th_model->request_queue, request) < 0) {
         destroy_request_item(&request);
         av_log(th_model->ctx, AV_LOG_ERROR, "Unable to push back request_queue when failed to start inference.\n");
@@ -486,6 +531,7 @@ static DNNModel *dnn_load_model_th(DnnContext *ctx, DNNFunctionType func_type, A
     THModel *th_model = NULL;
     THRequestItem *item = NULL;
     torch::jit::NameTensor first_param;
+    torch::jit::Module *jit_model;
     const char *device_name = ctx->device ? ctx->device : "cpu";
 
     th_model = (THModel *)av_mallocz(sizeof(THModel));
@@ -494,30 +540,42 @@ static DNNModel *dnn_load_model_th(DnnContext *ctx, DNNFunctionType func_type, A
     model = &th_model->model;
     th_model->ctx = ctx;
 
-    c10::Device device = c10::Device(device_name);
-    if (device.is_cpu()) {
-         th_model->device_type = torch::kCPU;
-    } else if (device.is_xpu()) {
-        if (!at::hasXPU()) {
-            av_log(ctx, AV_LOG_ERROR, "No XPU device found\n");
-            return NULL;
-        }
-        at::detail::getXPUHooks().initXPU();
-        th_model->device_type = torch::kXPU;
-     } else {
-         av_log(ctx, AV_LOG_ERROR, "Not supported device:\"%s\"\n", device_name);
-         goto fail;
-     }
-
-    try {
-        th_model->jit_model = new torch::jit::Module;
-        (*th_model->jit_model) = torch::jit::load(ctx->model_filename);
-        th_model->jit_model->to(th_model->device_type);
-    } catch (const c10::Error& e) {
-        av_log(ctx, AV_LOG_ERROR, "Failed to load torch model\n");
+    th_model->device_names = th_separate_device_name(ctx->device, &th_model->nb_models);
+    if (!th_model->device_names) {
+        av_log(ctx, AV_LOG_ERROR, "could not parse devices names\n");
+        return NULL;
+    }
+
+    th_model->jit_model_queue = ff_safe_queue_create();
+    if (!th_model->jit_model_queue) {
         goto fail;
     }
-    first_param = *th_model->jit_model->named_parameters().begin();
+    for (int i = 0; i < th_model->nb_models; i++) {
+        c10::Device *device;
+        device = new c10::Device(th_model->device_names[i]);
+        if (device && device->is_xpu()) {
+            if (!at::hasXPU()) {
+                av_log(ctx, AV_LOG_ERROR, "No XPU device found\n");
+                delete device;
+                goto fail;
+            }
+            at::detail::getXPUHooks().initXPU();
+        }
+
+        try {
+            jit_model = new torch::jit::Module;
+            *jit_model = torch::jit::load(ctx->model_filename);
+            jit_model->to(*device);
+        } catch (const c10::Error& e) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to load torch model\n");
+            goto fail;
+        }
+        if (ff_safe_queue_push_back(th_model->jit_model_queue, jit_model) < 0) {
+           delete jit_model;
+           goto fail;
+        }
+    }
+    first_param = *jit_model->named_parameters().begin();
 
 #if !HAVE_PTHREAD_CANCEL
     if (ctx->options.async) {
@@ -532,7 +590,7 @@ static DNNModel *dnn_load_model_th(DnnContext *ctx, DNNFunctionType func_type, A
     }
 
     if (ctx->nireq <= 0)
-        ctx->nireq = 1;
+        ctx->nireq = th_model->nb_models;
 
     for (int i = 0; i < ctx->nireq; i++) {
         item = (THRequestItem *)av_mallocz(sizeof(THRequestItem));
-- 
2.34.1

