From 279b7bed229342606a6818c5115051f6d3055e7f Mon Sep 17 00:00:00 2001
From: Ting Fu <ting.fu@intel.com>
Date: Mon, 18 Jul 2022 10:13:04 +0800
Subject: [PATCH] lavfi: add LibTorch backend multi-frame inference support

Dnn models may take multiple frames as one input, so add "nb_input"
option to control input frame number. Use queue to buffer the input
frames and send to model at once.

Signed-off-by: Ting Fu <ting.fu@intel.com>
Signed-off-by: Wenbin Chen <wenbin.chen@intel.com>
---
 libavfilter/dnn/dnn_backend_common.c   | 20 ++++++-
 libavfilter/dnn/dnn_backend_common.h   |  3 +
 libavfilter/dnn/dnn_backend_openvino.c |  2 +-
 libavfilter/dnn/dnn_backend_tf.c       |  2 +-
 libavfilter/dnn/dnn_backend_torch.cpp  | 39 ++++++++++--
 libavfilter/dnn/dnn_interface.c        |  2 +
 libavfilter/dnn_filter_common.c        | 83 +++++++++++++++++++++++---
 libavfilter/dnn_interface.h            | 10 +++-
 libavfilter/vf_dnn_processing.c        |  1 +
 9 files changed, 143 insertions(+), 19 deletions(-)

diff --git a/libavfilter/dnn/dnn_backend_common.c b/libavfilter/dnn/dnn_backend_common.c
index e45eefd14d..6eb90ba963 100644
--- a/libavfilter/dnn/dnn_backend_common.c
+++ b/libavfilter/dnn/dnn_backend_common.c
@@ -60,7 +60,10 @@ int ff_dnn_fill_task(TaskItem *task, DNNExecBaseParams *exec_params, void *backe
     task->input_name = exec_params->input_name;
     task->in_frame = exec_params->in_frame;
     task->out_frame = exec_params->out_frame;
+    task->in_queue = exec_params->in_queue;
+    task->out_queue = exec_params->out_queue;
     task->model = backend_model;
+    task->nb_input = exec_params->nb_input;
     task->nb_output = exec_params->nb_output;
     task->output_names = exec_params->output_names;
 
@@ -147,8 +150,21 @@ DNNAsyncStatusType ff_dnn_get_result_common(Queue *task_queue, AVFrame **in, AVF
 
     *in = task->in_frame;
     *out = task->out_frame;
-    ff_queue_pop_front(task_queue);
-    av_freep(&task);
+    if (task->in_queue || task->out_queue) {
+        if (av_fifo_can_read(task->out_queue))
+            av_fifo_read(task->out_queue, out, 1);
+        if (av_fifo_can_read(task->in_queue))
+            av_fifo_read(task->in_queue, in, 1);
+        if (!av_fifo_can_read(task->out_queue) && !av_fifo_can_read(task->in_queue)) {
+            ff_queue_pop_front(task_queue);
+            av_fifo_freep2(&task->in_queue);
+            av_fifo_freep2(&task->out_queue);
+            av_freep(&task);
+        }
+    } else {
+        ff_queue_pop_front(task_queue);
+        av_freep(&task);
+    }
 
     return DAST_SUCCESS;
 }
diff --git a/libavfilter/dnn/dnn_backend_common.h b/libavfilter/dnn/dnn_backend_common.h
index 9f5d37b3e0..2844804b36 100644
--- a/libavfilter/dnn/dnn_backend_common.h
+++ b/libavfilter/dnn/dnn_backend_common.h
@@ -44,10 +44,13 @@ typedef struct TaskItem {
     void *model; // model for the backend
     AVFrame *in_frame;
     AVFrame *out_frame;
+    AVFifo *in_queue;
+    AVFifo *out_queue;
     const char *input_name;
     const char **output_names;
     uint8_t async;
     uint8_t do_ioproc;
+    uint32_t nb_input;
     uint32_t nb_output;
     uint32_t inference_todo;
     uint32_t inference_done;
diff --git a/libavfilter/dnn/dnn_backend_openvino.c b/libavfilter/dnn/dnn_backend_openvino.c
index 9c699cdc8c..1004b26985 100644
--- a/libavfilter/dnn/dnn_backend_openvino.c
+++ b/libavfilter/dnn/dnn_backend_openvino.c
@@ -1255,7 +1255,7 @@ static int extract_lltask_from_task(DNNFunctionType func_type, TaskItem *task, Q
     }
 }
 
-static int get_output_ov(DNNModel *model, const char *input_name, int input_width, int input_height,
+static int get_output_ov(DNNModel *model, const char *input_name, int input_width, int input_height, int nb_input,
                                    const char *output_name, int *output_width, int *output_height)
 {
 #if HAVE_OPENVINO2
diff --git a/libavfilter/dnn/dnn_backend_tf.c b/libavfilter/dnn/dnn_backend_tf.c
index 6afefe8115..aca113bccc 100644
--- a/libavfilter/dnn/dnn_backend_tf.c
+++ b/libavfilter/dnn/dnn_backend_tf.c
@@ -310,7 +310,7 @@ static int get_input_tf(DNNModel *model, DNNData *input, const char *input_name)
     return 0;
 }
 
-static int get_output_tf(DNNModel *model, const char *input_name, int input_width, int input_height,
+static int get_output_tf(DNNModel *model, const char *input_name, int input_width, int input_height, int nb_input,
                                    const char *output_name, int *output_width, int *output_height)
 {
     int ret;
diff --git a/libavfilter/dnn/dnn_backend_torch.cpp b/libavfilter/dnn/dnn_backend_torch.cpp
index c70d32904f..47ec6d4ea6 100644
--- a/libavfilter/dnn/dnn_backend_torch.cpp
+++ b/libavfilter/dnn/dnn_backend_torch.cpp
@@ -30,6 +30,7 @@ extern "C" {
 #include "../internal.h"
 #include "dnn_io_proc.h"
 #include "dnn_backend_common.h"
+#include "libavutil/fifo.h"
 #include "libavutil/opt.h"
 #include "libavutil/mem.h"
 #include "queue.h"
@@ -173,6 +174,9 @@ static int fill_model_input_th(THModel *th_model, THRequestItem *request)
     DNNData input = { 0 };
     DnnContext *ctx = th_model->ctx;
     int ret, width_idx, height_idx, channel_idx;
+    size_t offset = 0;
+    AVFrame *tmp_frame = NULL;
+    void *in_data;
 
     lltask = (LastLevelTaskItem *)ff_queue_pop_front(th_model->lltask_queue);
     if (!lltask) {
@@ -193,9 +197,10 @@ static int fill_model_input_th(THModel *th_model, THRequestItem *request)
     input.dims[height_idx] = task->in_frame->height;
     input.dims[width_idx] = task->in_frame->width;
     input.data = av_malloc(input.dims[height_idx] * input.dims[width_idx] *
-                           input.dims[channel_idx] * sizeof(float));
+                           input.dims[channel_idx] * sizeof(float) * task->nb_input);
     if (!input.data)
         return AVERROR(ENOMEM);
+    in_data = input.data;
     infer_request->input_tensor = new torch::Tensor();
     infer_request->output = new torch::Tensor();
 
@@ -206,7 +211,15 @@ static int fill_model_input_th(THModel *th_model, THRequestItem *request)
             if (th_model->model.frame_pre_proc != NULL) {
                 th_model->model.frame_pre_proc(task->in_frame, &input, th_model->model.filter_ctx);
             } else {
-                ff_proc_from_frame_to_dnn(task->in_frame, &input, ctx);
+                size_t in_queue_nb = av_fifo_can_read(task->in_queue);
+                do {
+                    av_fifo_peek(task->in_queue, &tmp_frame, 1,
+                                 offset >= in_queue_nb ? in_queue_nb - 1 : offset);
+                    ff_proc_from_frame_to_dnn(tmp_frame, &input, ctx);
+                    input.data += input.dims[height_idx] * input.dims[width_idx] * input.dims[channel_idx] * sizeof(float);
+                    offset++;
+                } while (task->nb_input > offset);
+                input.data = in_data;
             }
         }
         break;
@@ -220,7 +233,7 @@ static int fill_model_input_th(THModel *th_model, THRequestItem *request)
             deleter, torch::kFloat32);
     } else {
         *infer_request->input_tensor = torch::from_blob(input.data,
-            {1, input.dims[channel_idx], input.dims[height_idx], input.dims[width_idx]},
+            {1, task->nb_input, input.dims[channel_idx], input.dims[height_idx], input.dims[width_idx]},
             deleter, torch::kFloat32);
     }
     if (infer_request->input_tensor->device() != th_model->device_type)
@@ -296,6 +309,8 @@ static void infer_completion_callback(void *args) {
     THInferRequest *infer_request = request->infer_request;
     THModel *th_model = (THModel *)task->model;
     torch::Tensor *output = infer_request->output;
+    AVFrame *tmp_frame = NULL;
+    size_t offset = 0;
 
     c10::IntArrayRef sizes = output->sizes();
     outputs.order = DCO_RGB;
@@ -308,6 +323,13 @@ static void infer_completion_callback(void *args) {
         outputs.dims[1] = sizes.at(1); // C
         outputs.dims[2] = sizes.at(2); // H
         outputs.dims[3] = sizes.at(3); // W
+    } else if (sizes.size() == 5) {
+        // 4 dimensions: [batch_size, frame_number, channel, height, width]
+        // this format of data is normally used for video frame SR
+        outputs.dims[0] = sizes.at(0); // N
+        outputs.dims[1] = sizes.at(2); // C
+        outputs.dims[2] = sizes.at(3); // H
+        outputs.dims[3] = sizes.at(4); // W
     } else {
         avpriv_report_missing_feature(th_model->ctx, "Support of this kind of model");
         goto err;
@@ -324,7 +346,13 @@ static void infer_completion_callback(void *args) {
             if (th_model->model.frame_post_proc != NULL) {
                 th_model->model.frame_post_proc(task->out_frame, &outputs, th_model->model.filter_ctx);
             } else {
-                ff_proc_from_dnn_to_frame(task->out_frame, &outputs, th_model->ctx);
+                do {
+                    av_fifo_peek(task->out_queue, &tmp_frame, 1, offset);
+                    ff_proc_from_dnn_to_frame(tmp_frame, &outputs, &th_model->ctx);
+                    outputs.data += outputs.dims[1] * outputs.dims[2] * outputs.dims[3] * sizeof(float);
+                    offset++;
+                } while (av_fifo_can_read(task->out_queue) > offset);
+                task->out_frame = NULL;
             }
         } else {
             task->out_frame->width = outputs.dims[dnn_get_width_idx_by_layout(outputs.layout)];
@@ -390,7 +418,7 @@ err:
     return ret;
 }
 
-static int get_output_th(DNNModel *model, const char *input_name, int input_width, int input_height,
+static int get_output_th(DNNModel *model, const char *input_name, int input_width, int input_height, int nb_input,
                                    const char *output_name, int *output_width, int *output_height)
 {
     int ret = 0;
@@ -401,6 +429,7 @@ static int get_output_th(DNNModel *model, const char *input_name, int input_widt
     DNNExecBaseParams exec_params = {
         .input_name     = input_name,
         .output_names   = &output_name,
+        .nb_input       = (uint32_t)nb_input,
         .nb_output      = 1,
         .in_frame       = NULL,
         .out_frame      = NULL,
diff --git a/libavfilter/dnn/dnn_interface.c b/libavfilter/dnn/dnn_interface.c
index 8dec3b671a..7fa788290c 100644
--- a/libavfilter/dnn/dnn_interface.c
+++ b/libavfilter/dnn/dnn_interface.c
@@ -40,6 +40,8 @@ static const AVOption dnn_base_options[] = {
                 OFFSET(model_filename), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 0, FLAGS},
         {"input", "input name of the model",
                 OFFSET(model_inputname), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 0, FLAGS},
+        { "input_nb", "input number of the mode",
+                OFFSET(nb_inputs), AV_OPT_TYPE_INT, { .i64 = 1 }, 0, INT_MAX, FLAGS },
         {"output", "output name of the model",
                 OFFSET(model_outputnames_string), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 0, FLAGS},
         {"backend_configs", "backend configs (deprecated)",
diff --git a/libavfilter/dnn_filter_common.c b/libavfilter/dnn_filter_common.c
index 6b9c6f8d7f..a06279e2d1 100644
--- a/libavfilter/dnn_filter_common.c
+++ b/libavfilter/dnn_filter_common.c
@@ -79,6 +79,8 @@ int ff_dnn_init(DnnContext *ctx, DNNFunctionType func_type, AVFilterContext *fil
         return AVERROR(EINVAL);
     }
 
+    ctx->nb_inputs  = ctx->nb_inputs <= 0 ? 1 : ctx->nb_inputs;
+
     if (backend == DNN_TH) {
         if (ctx->model_inputname)
             av_log(filter_ctx, AV_LOG_WARNING, "LibTorch backend do not require inputname, "\
@@ -164,20 +166,49 @@ int ff_dnn_get_output(DnnContext *ctx, int input_width, int input_height, int *o
 {
     char * output_name = ctx->model_outputnames && ctx->backend_type != DNN_TH ?
                          ctx->model_outputnames[0] : NULL;
-    return ctx->model->get_output(ctx->model, ctx->model_inputname, input_width, input_height,
+    return ctx->model->get_output(ctx->model, ctx->model_inputname, input_width, input_height, ctx->nb_inputs,
                                   (const char *)output_name, output_width, output_height);
 }
 
 int ff_dnn_execute_model(DnnContext *ctx, AVFrame *in_frame, AVFrame *out_frame)
 {
-    DNNExecBaseParams exec_params = {
-        .input_name     = ctx->model_inputname,
-        .output_names   = (const char **)ctx->model_outputnames,
-        .nb_output      = ctx->nb_outputs,
-        .in_frame       = in_frame,
-        .out_frame      = out_frame,
-    };
-    return (ctx->dnn_module->execute_model)(ctx->model, &exec_params);
+    int ret = 0;
+    if (ctx->nb_inputs > 0) {
+        if (!ctx->in_queue) {
+            ctx->in_queue = av_fifo_alloc2(ctx->nb_inputs, sizeof(AVFrame *), AV_FIFO_FLAG_AUTO_GROW);
+            if (!ctx->in_queue)
+                return AVERROR(ENOMEM);
+        }
+        if (!ctx->out_queue) {
+            ctx->out_queue = av_fifo_alloc2(ctx->nb_inputs, sizeof(AVFrame *), AV_FIFO_FLAG_AUTO_GROW);
+            if (!ctx->out_queue)
+                return AVERROR(ENOMEM);
+        }
+        if (av_fifo_can_read(ctx->in_queue) < ctx->nb_inputs) {
+            ret = av_fifo_write(ctx->in_queue, &in_frame, 1);
+            if (ret < 0)
+                return ret;
+            ret = av_fifo_write(ctx->out_queue, &out_frame, 1);
+            if (ret < 0)
+                return ret;
+        }
+    }
+    if (!ctx->nb_inputs || av_fifo_can_read(ctx->in_queue) == ctx->nb_inputs) {
+        DNNExecBaseParams exec_params = {
+            .input_name     = ctx->model_inputname,
+            .output_names   = (const char **)ctx->model_outputnames,
+            .nb_input       = ctx->nb_inputs,
+            .nb_output      = ctx->nb_outputs,
+            .in_frame       = in_frame,
+            .out_frame      = out_frame,
+            .in_queue       = ctx->in_queue,
+            .out_queue      = ctx->out_queue,
+        };
+        ctx->in_queue = NULL;
+        ctx->out_queue = NULL;
+        return (ctx->dnn_module->execute_model)(ctx->model, &exec_params);
+    } else
+        return 0;
 }
 
 int ff_dnn_execute_model_classification(DnnContext *ctx, AVFrame *in_frame, AVFrame *out_frame, const char *target)
@@ -202,11 +233,45 @@ DNNAsyncStatusType ff_dnn_get_result(DnnContext *ctx, AVFrame **in_frame, AVFram
 
 int ff_dnn_flush(DnnContext *ctx)
 {
+    if (ctx->in_queue && av_fifo_can_read(ctx->in_queue) &&
+        ctx->out_queue && av_fifo_can_read(ctx->out_queue)) {
+        DNNExecBaseParams exec_params = {
+            .input_name     = ctx->model_inputname,
+            .output_names   = (const char **)ctx->model_outputnames,
+            .nb_input       = ctx->nb_inputs,
+            .nb_output      = ctx->nb_outputs,
+            .in_queue       = ctx->in_queue,
+            .out_queue      = ctx->out_queue,
+        };
+        av_fifo_peek(ctx->in_queue, &exec_params.in_frame, 1,
+                     av_fifo_can_read(ctx->in_queue) - 1);
+        av_fifo_peek(ctx->out_queue, &exec_params.out_frame, 1,
+                     av_fifo_can_read(ctx->out_queue) - 1);
+        ctx->in_queue = NULL;
+        ctx->out_queue = NULL;
+        if ((ctx->dnn_module->execute_model)(ctx->model, &exec_params) != 0)
+            return AVERROR(EIO);
+    }
     return (ctx->dnn_module->flush)(ctx->model);
 }
 
 void ff_dnn_uninit(DnnContext *ctx)
 {
+    AVFrame *temp_frame;
+    if (ctx->in_queue) {
+        while (av_fifo_can_read(ctx->in_queue)) {
+            av_fifo_read(ctx->in_queue, &temp_frame, 1);
+            av_frame_free(&temp_frame);
+        }
+        av_fifo_freep2(&ctx->in_queue);
+    }
+    if (ctx->out_queue) {
+        while(av_fifo_can_read(ctx->out_queue)) {
+            av_fifo_read(ctx->out_queue, &temp_frame, 1);
+            av_frame_free(&temp_frame);
+        }
+        av_fifo_freep2(&ctx->out_queue);
+    }
     if (ctx->dnn_module) {
         (ctx->dnn_module->free_model)(&ctx->model);
     }
diff --git a/libavfilter/dnn_interface.h b/libavfilter/dnn_interface.h
index 66086409be..5a7c26fb1b 100644
--- a/libavfilter/dnn_interface.h
+++ b/libavfilter/dnn_interface.h
@@ -28,6 +28,7 @@
 
 #include <stdint.h>
 #include "libavutil/frame.h"
+#include "libavutil/fifo.h"
 #include "avfilter.h"
 
 #define DNN_GENERIC_ERROR FFERRTAG('D','N','N','!')
@@ -80,9 +81,12 @@ typedef struct DNNData{
 typedef struct DNNExecBaseParams {
     const char *input_name;
     const char **output_names;
+    uint32_t nb_input;
     uint32_t nb_output;
     AVFrame *in_frame;
     AVFrame *out_frame;
+    AVFifo *in_queue;
+    AVFifo *out_queue;
 } DNNExecBaseParams;
 
 typedef struct DNNExecClassificationParams {
@@ -103,7 +107,7 @@ typedef struct DNNModel{
     // Just reuse struct DNNData here, actually the DNNData.data field is not needed.
     int (*get_input)(struct DNNModel *model, DNNData *input, const char *input_name);
     // Gets model output width/height with given input w/h
-    int (*get_output)(struct DNNModel *model, const char *input_name, int input_width, int input_height,
+    int (*get_output)(struct DNNModel *model, const char *input_name, int input_width, int input_height, int nb_input,
                                 const char *output_name, int *output_width, int *output_height);
     // set the pre process to transfer data from AVFrame to DNNData
     // the default implementation within DNN is used if it is not provided by the filter
@@ -153,6 +157,7 @@ typedef struct DnnContext {
     int async;
 
     char **model_outputnames;
+    uint32_t nb_inputs;
     uint32_t nb_outputs;
     const DNNModule *dnn_module;
 
@@ -169,6 +174,9 @@ typedef struct DnnContext {
 #if CONFIG_LIBTORCH
     THOptions torch_option;
 #endif
+
+    AVFifo *in_queue;
+    AVFifo *out_queue;
 } DnnContext;
 
 // Stores pointers to functions for loading, executing, freeing DNN models for one of the backends.
diff --git a/libavfilter/vf_dnn_processing.c b/libavfilter/vf_dnn_processing.c
index 7c0f84ec80..146f46190e 100644
--- a/libavfilter/vf_dnn_processing.c
+++ b/libavfilter/vf_dnn_processing.c
@@ -27,6 +27,7 @@
 #include "libavutil/pixdesc.h"
 #include "libavutil/avassert.h"
 #include "libavutil/imgutils.h"
+#include "libavutil/fifo.h"
 #include "filters.h"
 #include "dnn_filter_common.h"
 #include "internal.h"
-- 
2.34.1

