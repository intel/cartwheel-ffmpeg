From bf6812ea9f780401c02c0d4015ad898576d6f4e3 Mon Sep 17 00:00:00 2001
From: Wenbin Chen <wenbin.chen@intel.com>
Date: Tue, 14 Nov 2023 16:38:52 +0800
Subject: [PATCH] libavfilter/dnn/dnn_backend_torch: Add async to torch backend

Signed-off-by: Wenbin Chen <wenbin.chen@intel.com>
---
 libavfilter/dnn/dnn_backend_torch.cpp | 55 ++++++++++++++++++---------
 1 file changed, 37 insertions(+), 18 deletions(-)

diff --git a/libavfilter/dnn/dnn_backend_torch.cpp b/libavfilter/dnn/dnn_backend_torch.cpp
index 47ec6d4ea6..da1d07409b 100644
--- a/libavfilter/dnn/dnn_backend_torch.cpp
+++ b/libavfilter/dnn/dnn_backend_torch.cpp
@@ -69,6 +69,8 @@ static const AVOption dnn_th_options[] = {
     { NULL }
 };
 
+static void dnn_free_model_th(DNNModel **model);
+
 static int extract_lltask_from_task(TaskItem *task, Queue *lltask_queue)
 {
     THModel *th_model = (THModel *)task->model;
@@ -380,6 +382,7 @@ static int execute_model_th(THRequestItem *request, Queue *lltask_queue)
     LastLevelTaskItem *lltask;
     TaskItem *task = NULL;
     int ret = 0;
+    DnnContext *ctx;
 
     if (ff_queue_size(lltask_queue) == 0) {
         destroy_request_item(&request);
@@ -394,13 +397,17 @@ static int execute_model_th(THRequestItem *request, Queue *lltask_queue)
     }
     task = lltask->task;
     th_model = (THModel *)task->model;
+    ctx = th_model->ctx;
 
     ret = fill_model_input_th(th_model, request);
     if ( ret != 0) {
         goto err;
     }
     if (task->async) {
-        avpriv_report_missing_feature(th_model->ctx, "LibTorch async");
+        if (ff_dnn_start_inference_async(ctx, &request->exec_module) != 0) {
+            goto err;
+        }
+        return 0;
     } else {
         ret = th_start_inference((void *)(request));
         if (ret != 0) {
@@ -512,29 +519,41 @@ static DNNModel *dnn_load_model_th(DnnContext *ctx, DNNFunctionType func_type, A
     }
     first_param = *th_model->jit_model->named_parameters().begin();
 
+#if !HAVE_PTHREAD_CANCEL
+    if (ctx->options.async) {
+        ctx->options.async = 0;
+        av_log(filter_ctx, AV_LOG_WARNING, "pthread is not supported, roll back to sync.\n");
+    }
+#endif
+
     th_model->request_queue = ff_safe_queue_create();
     if (!th_model->request_queue) {
         goto fail;
     }
 
-    item = (THRequestItem *)av_mallocz(sizeof(THRequestItem));
-    if (!item) {
-        goto fail;
-    }
-    item->lltask = NULL;
-    item->infer_request = th_create_inference_request();
-    if (!item->infer_request) {
-        av_log(NULL, AV_LOG_ERROR, "Failed to allocate memory for Torch inference request\n");
-        goto fail;
-    }
-    item->exec_module.start_inference = &th_start_inference;
-    item->exec_module.callback = &infer_completion_callback;
-    item->exec_module.args = item;
+    if (ctx->nireq <= 0)
+        ctx->nireq = 1;
 
-    if (ff_safe_queue_push_back(th_model->request_queue, item) < 0) {
-        goto fail;
+    for (int i = 0; i < ctx->nireq; i++) {
+        item = (THRequestItem *)av_mallocz(sizeof(THRequestItem));
+        if (!item) {
+            goto fail;
+        }
+        item->lltask = NULL;
+        item->infer_request = th_create_inference_request();
+        if (!item->infer_request) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to allocate memory for Torch inference request\n");
+            goto fail;
+        }
+        item->exec_module.start_inference = &th_start_inference;
+        item->exec_module.callback = &infer_completion_callback;
+        item->exec_module.args = item;
+
+        if (ff_safe_queue_push_back(th_model->request_queue, item) < 0) {
+            goto fail;
+        }
+        item = NULL;
     }
-    item = NULL;
 
     th_model->task_queue = ff_queue_create();
     if (!th_model->task_queue) {
@@ -589,7 +608,7 @@ static int dnn_execute_model_th(const DNNModel *model, DNNExecBaseParams *exec_p
         return AVERROR(ENOMEM);
     }
 
-    ret = ff_dnn_fill_task(task, exec_params, th_model, 0, 1);
+    ret = ff_dnn_fill_task(task, exec_params, th_model, ctx->async, 1);
     if (ret != 0) {
         av_freep(&task);
         av_log(ctx, AV_LOG_ERROR, "unable to fill task.\n");
-- 
2.34.1

