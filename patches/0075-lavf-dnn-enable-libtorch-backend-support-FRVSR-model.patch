From 5525b107e650ea48a523d7be82971f8048b58259 Mon Sep 17 00:00:00 2001
From: Ting Fu <ting.fu@intel.com>
Date: Wed, 29 Jun 2022 07:46:44 +0000
Subject: [PATCH] lavf/dnn: enable libtorch backend support FRVSR model

Signed-off-by: Ting Fu <ting.fu@intel.com>
---
 libavfilter/dnn/dnn_backend_torch.cpp | 53 +++++++++++++++++++++++----
 1 file changed, 46 insertions(+), 7 deletions(-)

diff --git a/libavfilter/dnn/dnn_backend_torch.cpp b/libavfilter/dnn/dnn_backend_torch.cpp
index 34560dbfd2..06608f7a92 100644
--- a/libavfilter/dnn/dnn_backend_torch.cpp
+++ b/libavfilter/dnn/dnn_backend_torch.cpp
@@ -45,6 +45,8 @@ typedef struct THContext {
     THOptions options;
 } THContext;
 
+typedef enum {UNKNOWN_MODEL = -1, BASICVSR, FRVSR} ModelType;
+
 typedef struct THModel {
     THContext ctx;
     DNNModel *model;
@@ -52,6 +54,7 @@ typedef struct THModel {
     SafeQueue *request_queue;
     Queue *task_queue;
     Queue *lltask_queue;
+    ModelType model_type;
 } THModel;
 
 typedef struct THInferRequest {
@@ -198,6 +201,7 @@ static DNNModel *dnn_load_model_th(const char *model_filename, DNNFunctionType f
     THModel *th_model = NULL;
     THRequestItem *item = NULL;
     THContext *ctx;
+    torch::jit::NameTensor first_param;
 
     model = (DNNModel *)av_mallocz(sizeof(DNNModel));
     if (!model) {
@@ -240,6 +244,7 @@ static DNNModel *dnn_load_model_th(const char *model_filename, DNNFunctionType f
         av_log(ctx, AV_LOG_ERROR, "Failed to load torch model\n");
         goto fail;
     }
+    first_param = *th_model->jit_model.named_parameters().begin();
 
     th_model->request_queue = ff_safe_queue_create();
     if (!th_model->request_queue) {
@@ -274,6 +279,13 @@ static DNNModel *dnn_load_model_th(const char *model_filename, DNNFunctionType f
         goto fail;
     }
 
+    if (!first_param.name.find("fnet")) {
+        th_model->model_type = FRVSR;
+    } else if (!first_param.name.find("spynet")) {
+        th_model->model_type = BASICVSR;
+    } else {
+        th_model->model_type = UNKNOWN_MODEL;
+    }
     th_model->model = model;
     model->model = th_model;
     model->get_input = &get_input_th;
@@ -339,8 +351,13 @@ static int fill_model_input_th(THModel *th_model, THRequestItem *request)
         avpriv_report_missing_feature(NULL, "model function type %d", th_model->model->func_type);
         break;
     }
-    *infer_request->input_tensor = torch::from_blob(input.data, {1, 1, 3, input.height, input.width},
-                                                    torch::kFloat32);
+    if (th_model->model_type == FRVSR) {
+        *infer_request->input_tensor = torch::from_blob(input.data, {1, 3, input.height, input.width},
+                                                        torch::kFloat32);
+    } else {
+        *infer_request->input_tensor = torch::from_blob(input.data, {1, 1, 3, input.height, input.width},
+                                                        torch::kFloat32);
+    }
     if (infer_request->input_tensor->device() != ctx->options.device_type)
         *infer_request->input_tensor = infer_request->input_tensor->to(ctx->options.device_type);
     return 0;
@@ -359,6 +376,7 @@ static int th_start_inference(void *args)
     THModel *th_model = NULL;
     THContext *ctx = NULL;
     std::vector<torch::jit::IValue> inputs;
+    c10::DeviceType device_type;
 
     if (!request) {
         av_log(NULL, AV_LOG_ERROR, "THRequestItem is NULL\n");
@@ -369,14 +387,31 @@ static int th_start_inference(void *args)
     task = lltask->task;
     th_model = (THModel *)task->model;
     ctx = &th_model->ctx;
+    device_type = ctx->options.device_type;
 
     if (!infer_request->input_tensor || !infer_request->output) {
         av_log(ctx, AV_LOG_ERROR, "input or output tensor is NULL\n");
         return DNN_GENERIC_ERROR;
     }
     inputs.push_back(*infer_request->input_tensor);
-
-    *infer_request->output = th_model->jit_model.forward(inputs).toTensor();
+    if (th_model->model_type == FRVSR) {
+        auto size = infer_request->input_tensor->sizes();
+        int height = size[2];
+        int width  = size[3];
+        torch::Tensor lr_prev = torch::zeros({1, 3, height, width}, torch::TensorOptions().dtype(torch::kFloat32)
+                                                                                          .device(device_type));
+        torch::Tensor hr_prev = torch::zeros({1, 3, height * 4, width * 4}, torch::TensorOptions().dtype(torch::kFloat32)
+                                                                                                  .device(device_type));
+        inputs.push_back(lr_prev);
+        inputs.push_back(hr_prev);
+    }
+
+    auto outputs = th_model->jit_model.forward(inputs);
+    if (th_model->model_type == FRVSR) {
+        *infer_request->output = outputs.toTuple()->elements()[0].toTensor();
+    } else {
+        *infer_request->output = outputs.toTensor();
+    }
 
     return 0;
 }
@@ -391,10 +426,14 @@ static void infer_completion_callback(void *args) {
     torch::Tensor *output = infer_request->output;
 
     c10::IntArrayRef sizes = output->sizes();
-    assert(sizes.size == 5);
+    if (th_model->model_type == FRVSR) {
+        outputs.height = sizes.at(2);
+        outputs.width = sizes.at(3);
+    } else {
+        outputs.height = sizes.at(3);
+        outputs.width = sizes.at(4);
+    }
     outputs.order = DCO_RGB_PLANAR;
-    outputs.height = sizes.at(3);
-    outputs.width = sizes.at(4);
     outputs.dt = DNN_FLOAT;
     outputs.channels = 3;
 
-- 
2.34.1

